{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae65e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Loading model: prithivMLmods/Realistic-Gender-Classification\n",
      "‚úÖ Model loaded successfully.\n",
      "\n",
      "üß† Found 235 face images to process...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting gender (SigLIP2): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 235/235 [01:36<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Saved 235 results to ..\\data\\predictions\\cafe_pos\\20251107\\gender_annotated\\gender_predictions.csv\n",
      "üì∏ Annotated images saved to ..\\data\\predictions\\cafe_pos\\20251107\\gender_annotated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>predicted_gender</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cluster_000_AccoID_1170854_20251107_091623.png</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cluster_001_AccoID_1171262_20251107_112821.png</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cluster_002_AccoID_1171659_20251107_135038.png</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cluster_004_AccoID_1171659_20251107_135011.png</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cluster_006_AccoID_1171574_20251107_132453.png</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file predicted_gender  confidence\n",
       "0  cluster_000_AccoID_1170854_20251107_091623.png           Female       0.999\n",
       "1  cluster_001_AccoID_1171262_20251107_112821.png           Female       0.970\n",
       "2  cluster_002_AccoID_1171659_20251107_135038.png           Female       0.948\n",
       "3  cluster_004_AccoID_1171659_20251107_135011.png           Female       0.911\n",
       "4  cluster_006_AccoID_1171574_20251107_132453.png             Male       0.785"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from transformers import AutoImageProcessor, SiglipForImageClassification\n",
    "\n",
    "# =========================================\n",
    "# 1Ô∏è‚É£ CONFIGURATION\n",
    "# =========================================\n",
    "MODEL_NAME = \"prithivMLmods/Realistic-Gender-Classification\"\n",
    "INPUT_DIR = Path(\"../data/crops_face/20251107/5_cafe_pos_faces_unique\")\n",
    "OUTPUT_CSV = Path(\"../data/predictions/cafe_pos/20251107/gender_annotated/gender_predictions.csv\")\n",
    "ANNOTATION_DIR = Path(\"../data/predictions/cafe_pos/20251107/gender_annotated\")\n",
    "ANNOTATION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# =========================================\n",
    "# 2Ô∏è‚É£ LOAD MODEL\n",
    "# =========================================\n",
    "print(f\"üì¶ Loading model: {MODEL_NAME}\")\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "model = SiglipForImageClassification.from_pretrained(MODEL_NAME).to(device)\n",
    "model.eval()\n",
    "print(\"‚úÖ Model loaded successfully.\\n\")\n",
    "\n",
    "# ID ‚Üí Label mapping\n",
    "id2label = {\n",
    "    \"0\": \"Female\",\n",
    "    \"1\": \"Male\"\n",
    "}\n",
    "\n",
    "# =========================================\n",
    "# 3Ô∏è‚É£ GENDER PREDICTION FUNCTION\n",
    "# =========================================\n",
    "def classify_gender(image_path):\n",
    "    \"\"\"\n",
    "    Classifies gender using SigLIP2-based model.\n",
    "    Returns (gender_label, confidence_score)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "        pred_id = int(np.argmax(probs))\n",
    "        gender = id2label[str(pred_id)]\n",
    "        confidence = float(probs[pred_id])\n",
    "\n",
    "        return gender, confidence\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing {image_path}: {e}\")\n",
    "        return \"Unknown\", 0.0\n",
    "\n",
    "# =========================================\n",
    "# 4Ô∏è‚É£ PROCESS IMAGES\n",
    "# =========================================\n",
    "images = sorted([f for f in INPUT_DIR.glob(\"*\") if f.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]])\n",
    "print(f\"üß† Found {len(images)} face images to process...\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for img_path in tqdm(images, desc=\"Predicting gender (SigLIP2)\"):\n",
    "    gender, conf = classify_gender(img_path)\n",
    "\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    label = f\"{gender} ({conf*100:.1f}%)\"\n",
    "    overlay = img.copy()\n",
    "    cv2.rectangle(overlay, (0, 0), (img.shape[1], 50), (0, 0, 0), -1)\n",
    "    annotated = cv2.addWeighted(overlay, 0.4, img, 0.6, 0)\n",
    "    cv2.putText(annotated, label, (15, 35), FONT, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    out_path = ANNOTATION_DIR / f\"{img_path.stem}_gender.jpg\"\n",
    "    cv2.imwrite(str(out_path), annotated, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "\n",
    "    results.append({\n",
    "        \"file\": img_path.name,\n",
    "        \"predicted_gender\": gender,\n",
    "        \"confidence\": round(conf, 3)\n",
    "    })\n",
    "\n",
    "# =========================================\n",
    "# 5Ô∏è‚É£ SAVE RESULTS\n",
    "# =========================================\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Saved {len(df)} results to {OUTPUT_CSV}\")\n",
    "print(f\"üì∏ Annotated images saved to {ANNOTATION_DIR}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dbcc1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded files:\n",
      " - Gender predictions: 287 rows\n",
      " - Stage 1 results: 796 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "gender_csv = \"../data/predictions/cafe_pos/20251105/gender_annotated/gender_predictions.csv\"\n",
    "results_stage1 = \"../results/20251105/results_faces_accounting_20251105.csv\"\n",
    "output_csv = \"../results/20251105/results_faces_accounting_20251105.csv\"\n",
    "\n",
    "# Load data\n",
    "gender_df = pd.read_csv(gender_csv)\n",
    "results_df = pd.read_csv(results_stage1)\n",
    "\n",
    "print(\"‚úÖ Loaded files:\")\n",
    "print(f\" - Gender predictions: {len(gender_df)} rows\")\n",
    "print(f\" - Stage 1 results: {len(results_df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "956ecb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure same column naming for merge\n",
    "gender_df.rename(columns={\"file\": \"image_name\"}, inplace=True)\n",
    "\n",
    "# Clean up naming (in case of directory paths)\n",
    "gender_df[\"image_name\"] = gender_df[\"image_name\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "results_df[\"image_name\"] = results_df[\"image_name\"].apply(lambda x: x.split(\"/\")[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce37b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = results_df.merge(\n",
    "    gender_df,\n",
    "    on=\"image_name\",\n",
    "    how=\"left\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3db35346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage 2 results with gender saved to: ../results/20251105/results_faces_accounting_20251105.csv\n"
     ]
    }
   ],
   "source": [
    "merged_df.to_csv(output_csv, index=False)\n",
    "print(f\"‚úÖ Stage 2 results with gender saved to: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12af4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_age_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
