{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7f7d9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 735 prediction rows, 61 survey rows.\n",
      "Survey cols after normalize: ['Time', 'InvNo', 'Sex', '1-10', '11-20', '21-30', '31-40', '41-55', '56-65', '66-80', '80+']\n",
      "\n",
      "‚úÖ Saved merged file: ../results/20251107/results_faces_accounting_20251107_final.csv\n",
      "Rows with survey: 384 / 894\n",
      "\n",
      "‚Äî Sanity checks ‚Äî\n",
      "Unique invoices in survey: 45\n",
      "InvNo nulls in pred_df: 24\n",
      "InvNo nulls in survey: 0\n",
      "\n",
      "Survey gender counts:\n",
      " survey_gender\n",
      "Female    300\n",
      "Male       84\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Survey age group counts:\n",
      " survey_age_group\n",
      "56-65    109\n",
      "31-40     96\n",
      "66-80     85\n",
      "41-55     55\n",
      "21-30     18\n",
      "80+       18\n",
      "11-20      3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ========= PATHS =========\n",
    "predictions_csv = \"../results/20251107/results_faces_accounting_20251107.csv\"\n",
    "survey_xlsx     = \"../survey/Survey_Cafe_7-11-2025.xlsx\"\n",
    "output_csv      = \"../results/20251107/results_faces_accounting_20251107_final.csv\"\n",
    "\n",
    "# ========= LOAD =========\n",
    "pred_df   = pd.read_csv(predictions_csv)\n",
    "survey_df = pd.read_excel(survey_xlsx)  # first sheet by default\n",
    "print(f\"Loaded {len(pred_df)} prediction rows, {len(survey_df)} survey rows.\")\n",
    "\n",
    "# ========= NORMALIZE SURVEY COLUMN NAMES =========\n",
    "def normalize_col(c: str) -> str:\n",
    "    c = str(c).strip()\n",
    "    # collapse multiple spaces and replace non-breaking spaces\n",
    "    c = re.sub(r\"\\s+\", \" \", c.replace(\"\\xa0\", \" \"))\n",
    "    # normalize unicode dashes to hyphen-minus '-'\n",
    "    c = c.replace(\"‚Äì\",\"-\").replace(\"‚Äî\",\"-\").replace(\"-\",\"-\")\n",
    "    return c\n",
    "\n",
    "survey_df.columns = [normalize_col(c) for c in survey_df.columns]\n",
    "print(\"Survey cols after normalize:\", list(survey_df.columns))\n",
    "\n",
    "# ========= FIND/RENAME INVOICE COLUMN TO 'InvNo' =========\n",
    "inv_candidates = [c for c in survey_df.columns if \"inv\" in c.lower()]\n",
    "if not inv_candidates:\n",
    "    raise KeyError(\"Could not find an invoice column (e.g. 'Inv No' / 'InvNo').\")\n",
    "inv_col = inv_candidates[0]\n",
    "if inv_col != \"InvNo\":\n",
    "    survey_df.rename(columns={inv_col: \"InvNo\"}, inplace=True)\n",
    "\n",
    "# ========= RENAME SEX/TIME COLUMNS FOR CONSISTENCY =========\n",
    "rename_map = {}\n",
    "if \"Sex\" in survey_df.columns:  rename_map[\"Sex\"]  = \"survey_gender\"\n",
    "if \"Time\" in survey_df.columns: rename_map[\"Time\"] = \"survey_time\"\n",
    "survey_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# ========= CANONICAL AGE HEADERS WE EXPECT AFTER NORMALIZATION =========\n",
    "# We'll pick whichever of these exist in the sheet.\n",
    "canonical_age_headers = [\"1-10\",\"11-20\",\"21-30\",\"31-40\",\"41-55\",\"56-65\",\"66-80\",\"80+\"]\n",
    "age_cols = [c for c in survey_df.columns if c in canonical_age_headers]\n",
    "if not age_cols:\n",
    "    # Fallback: regex discover columns that look like ranges like \"31-40\" or \"80+\"\n",
    "    age_cols = [c for c in survey_df.columns if re.match(r\"^\\s*\\d+\\s*-\\s*\\d+\\s*$\", c) or c.strip().endswith(\"+\")]\n",
    "if not age_cols:\n",
    "    raise KeyError(\"Could not detect age columns in the survey sheet.\")\n",
    "\n",
    "# ========= COMPUTE survey_age_group FROM 'X' MARKS =========\n",
    "def pick_age_group(row):\n",
    "    for col in age_cols:\n",
    "        val = str(row[col]).strip().upper()\n",
    "        if val == \"X\":   # your sheet uses 'X'\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "survey_df[\"survey_age_group\"] = survey_df.apply(pick_age_group, axis=1)\n",
    "\n",
    "# ========= KEEP ONLY WHAT WE NEED & COERCE TYPES =========\n",
    "need_cols = [\"InvNo\", \"survey_gender\", \"survey_age_group\"]\n",
    "if \"survey_time\" in survey_df.columns:\n",
    "    need_cols.append(\"survey_time\")\n",
    "survey = survey_df[need_cols].copy()\n",
    "\n",
    "# Ensure InvNo is numeric and comparable\n",
    "survey[\"InvNo\"] = pd.to_numeric(survey[\"InvNo\"], errors=\"coerce\")\n",
    "\n",
    "# ========= MAKE SURE PREDICTIONS ALSO HAVE InvNo =========\n",
    "if \"InvNo\" not in pred_df.columns:\n",
    "    # Try to extract from AccoDocNo like \"224673/155\" -> 155\n",
    "    if \"AccoDocNo\" in pred_df.columns:\n",
    "        pred_df[\"InvNo\"] = pred_df[\"AccoDocNo\"].astype(str).str.extract(r\"/(\\d+)\", expand=False)\n",
    "    else:\n",
    "        raise KeyError(\"pred_df has no 'InvNo' and no 'AccoDocNo' to extract it from.\")\n",
    "pred_df[\"InvNo\"] = pd.to_numeric(pred_df[\"InvNo\"], errors=\"coerce\")\n",
    "\n",
    "# ========= OPTIONAL: STANDARDIZE GENDER TEXT =========\n",
    "if \"survey_gender\" in survey.columns:\n",
    "    survey[\"survey_gender\"] = (\n",
    "        survey[\"survey_gender\"]\n",
    "        .astype(str).str.strip().str.upper()\n",
    "        .replace({\"M\":\"Male\",\"MALE\":\"Male\",\"F\":\"Female\",\"FEMALE\":\"Female\"})\n",
    "        .where(survey[\"survey_gender\"].notna(), None)\n",
    "    )\n",
    "\n",
    "# ========= MERGE (MANY ITEMS -> ONE SURVEY) =========\n",
    "merged = pred_df.merge(survey, on=\"InvNo\", how=\"left\")\n",
    "\n",
    "# ========= RULE-BASED RESOLUTION WHEN MULTIPLE SURVEYS PER INVOICE =========\n",
    "# We pick the survey respondent that best matches predicted_gender + predicted_age.\n",
    "def best_survey_for_item(row):\n",
    "    inv = row[\"InvNo\"]\n",
    "    sub = survey[survey[\"InvNo\"] == inv]\n",
    "    if sub.empty:\n",
    "        return pd.Series({\"survey_gender\": None, \"survey_age_group\": None, \"survey_time\": None})\n",
    "    if len(sub) == 1:\n",
    "        out = sub.iloc[0]\n",
    "        return pd.Series({\"survey_gender\": out.get(\"survey_gender\"),\n",
    "                          \"survey_age_group\": out.get(\"survey_age_group\"),\n",
    "                          \"survey_time\": out.get(\"survey_time\") if \"survey_time\" in sub.columns else None})\n",
    "    sub = sub.copy()\n",
    "    sub[\"score\"] = 0\n",
    "    if \"predicted_gender\" in row:\n",
    "        sub.loc[sub[\"survey_gender\"] == row[\"predicted_gender\"], \"score\"] += 1\n",
    "    if \"predicted_age\" in row:\n",
    "        sub.loc[sub[\"survey_age_group\"] == row[\"predicted_age\"], \"score\"] += 1\n",
    "    best = sub.sort_values([\"score\"], ascending=False).iloc[0]\n",
    "    return pd.Series({\"survey_gender\": best.get(\"survey_gender\"),\n",
    "                      \"survey_age_group\": best.get(\"survey_age_group\"),\n",
    "                      \"survey_time\": best.get(\"survey_time\") if \"survey_time\" in sub.columns else None})\n",
    "\n",
    "# Overwrite with the chosen respondent (row-wise)\n",
    "over = merged.apply(best_survey_for_item, axis=1)\n",
    "for c in [\"survey_gender\",\"survey_age_group\",\"survey_time\"]:\n",
    "    if c in over.columns:\n",
    "        merged[c] = over[c]\n",
    "\n",
    "merged[\"survey_completed\"] = merged[\"survey_gender\"].notna()\n",
    "\n",
    "# ========= SAVE & REPORT =========\n",
    "merged.to_csv(output_csv, index=False)\n",
    "print(f\"\\n‚úÖ Saved merged file: {output_csv}\")\n",
    "print(f\"Rows with survey: {merged['survey_completed'].sum()} / {len(merged)}\")\n",
    "\n",
    "print(\"\\n‚Äî Sanity checks ‚Äî\")\n",
    "print(\"Unique invoices in survey:\", survey[\"InvNo\"].nunique())\n",
    "print(\"InvNo nulls in pred_df:\", pred_df[\"InvNo\"].isna().sum())\n",
    "print(\"InvNo nulls in survey:\", survey[\"InvNo\"].isna().sum())\n",
    "print(\"\\nSurvey gender counts:\\n\", merged.loc[merged[\"survey_completed\"], \"survey_gender\"].value_counts(dropna=False))\n",
    "print(\"\\nSurvey age group counts:\\n\", merged.loc[merged[\"survey_completed\"], \"survey_age_group\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64bd580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b425bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detected encoding for predictions CSV: utf-8\n",
      "‚úÖ Loaded 735 prediction records (items) and 64 survey entries.\n",
      "\n",
      "üßæ Extracted InvNo from AccoDocNo ‚Äî sample:\n",
      "0    14.0\n",
      "1    14.0\n",
      "2    14.0\n",
      "3    14.0\n",
      "4    14.0\n",
      "Name: InvNo, dtype: float64 \n",
      "\n",
      "‚úÖ Using invoice column: 'Inv No'\n",
      "üîÅ Merged '66‚Äì80' and '80+' into single bracket.\n",
      "‚úÖ Survey cleaned ‚Äî 64 valid records with InvNo.\n",
      "\n",
      "\n",
      "‚úÖ Final merged file saved: ../results/20251107/results_faces_accounting_20251107_vit_final.csv\n",
      "üìä Total rows: 829 | Completed surveys: 294\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>AccoID</th>\n",
       "      <th>AccoDocNo</th>\n",
       "      <th>AccoDate</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>AccoAmount</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>...</th>\n",
       "      <th>StockDesciption</th>\n",
       "      <th>predicted_gender</th>\n",
       "      <th>confidence</th>\n",
       "      <th>predicted_age</th>\n",
       "      <th>age_confidence</th>\n",
       "      <th>InvNo</th>\n",
       "      <th>survey_gender</th>\n",
       "      <th>survey_age_group</th>\n",
       "      <th>survey_time</th>\n",
       "      <th>survey_completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cluster_000_AccoID_1170854_20251107_091623.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1170854</td>\n",
       "      <td>224882/14</td>\n",
       "      <td>2025-11-07 09:17:00</td>\n",
       "      <td>2025-11-07 09:16:23</td>\n",
       "      <td>-460.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>wors breakfast</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.999</td>\n",
       "      <td>21‚Äì30</td>\n",
       "      <td>0.742</td>\n",
       "      <td>14.0</td>\n",
       "      <td>F</td>\n",
       "      <td>41‚Äì55</td>\n",
       "      <td>08:57:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cluster_000_AccoID_1170854_20251107_091623.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1170854</td>\n",
       "      <td>224882/14</td>\n",
       "      <td>2025-11-07 09:17:00</td>\n",
       "      <td>2025-11-07 09:16:23</td>\n",
       "      <td>-460.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>plaas koffee</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.999</td>\n",
       "      <td>21‚Äì30</td>\n",
       "      <td>0.742</td>\n",
       "      <td>14.0</td>\n",
       "      <td>F</td>\n",
       "      <td>41‚Äì55</td>\n",
       "      <td>08:57:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cluster_000_AccoID_1170854_20251107_091623.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1170854</td>\n",
       "      <td>224882/14</td>\n",
       "      <td>2025-11-07 09:17:00</td>\n",
       "      <td>2025-11-07 09:16:23</td>\n",
       "      <td>-460.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>americano black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.999</td>\n",
       "      <td>21‚Äì30</td>\n",
       "      <td>0.742</td>\n",
       "      <td>14.0</td>\n",
       "      <td>F</td>\n",
       "      <td>41‚Äì55</td>\n",
       "      <td>08:57:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cluster_000_AccoID_1170854_20251107_091623.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1170854</td>\n",
       "      <td>224882/14</td>\n",
       "      <td>2025-11-07 09:17:00</td>\n",
       "      <td>2025-11-07 09:16:23</td>\n",
       "      <td>-460.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>cappuccino</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.999</td>\n",
       "      <td>21‚Äì30</td>\n",
       "      <td>0.742</td>\n",
       "      <td>14.0</td>\n",
       "      <td>F</td>\n",
       "      <td>41‚Äì55</td>\n",
       "      <td>08:57:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cluster_000_AccoID_1170854_20251107_091623.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1170854</td>\n",
       "      <td>224882/14</td>\n",
       "      <td>2025-11-07 09:17:00</td>\n",
       "      <td>2025-11-07 09:16:23</td>\n",
       "      <td>-460.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>lite</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.999</td>\n",
       "      <td>21‚Äì30</td>\n",
       "      <td>0.742</td>\n",
       "      <td>14.0</td>\n",
       "      <td>F</td>\n",
       "      <td>41‚Äì55</td>\n",
       "      <td>08:57:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cluster_000_AccoID_1170854_20251107_091623.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1170854</td>\n",
       "      <td>224882/14</td>\n",
       "      <td>2025-11-07 09:17:00</td>\n",
       "      <td>2025-11-07 09:16:23</td>\n",
       "      <td>-460.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>...</td>\n",
       "      <td>pbb peanut butter</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.999</td>\n",
       "      <td>21‚Äì30</td>\n",
       "      <td>0.742</td>\n",
       "      <td>14.0</td>\n",
       "      <td>F</td>\n",
       "      <td>41‚Äì55</td>\n",
       "      <td>08:57:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cluster_000_AccoID_1170854_20251107_091623.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1170854</td>\n",
       "      <td>224882/14</td>\n",
       "      <td>2025-11-07 09:17:00</td>\n",
       "      <td>2025-11-07 09:16:23</td>\n",
       "      <td>-460.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>hadeda</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.999</td>\n",
       "      <td>21‚Äì30</td>\n",
       "      <td>0.742</td>\n",
       "      <td>14.0</td>\n",
       "      <td>F</td>\n",
       "      <td>41‚Äì55</td>\n",
       "      <td>08:57:00</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cluster_001_AccoID_1171262_20251107_112821.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1171262</td>\n",
       "      <td>224949/77</td>\n",
       "      <td>2025-11-07 11:28:00</td>\n",
       "      <td>2025-11-07 11:28:21</td>\n",
       "      <td>-112.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>beef patty</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.970</td>\n",
       "      <td>31‚Äì40</td>\n",
       "      <td>0.448</td>\n",
       "      <td>77.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cluster_002_AccoID_1171659_20251107_135038.png</td>\n",
       "      <td>2</td>\n",
       "      <td>1171659</td>\n",
       "      <td>225013/151</td>\n",
       "      <td>2025-11-07 13:51:00</td>\n",
       "      <td>2025-11-07 13:50:38</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>...</td>\n",
       "      <td>cappuccino</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.948</td>\n",
       "      <td>21‚Äì30</td>\n",
       "      <td>0.543</td>\n",
       "      <td>151.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cluster_002_AccoID_1171659_20251107_135038.png</td>\n",
       "      <td>2</td>\n",
       "      <td>1171659</td>\n",
       "      <td>225013/151</td>\n",
       "      <td>2025-11-07 13:51:00</td>\n",
       "      <td>2025-11-07 13:50:38</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>just pops</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.948</td>\n",
       "      <td>21‚Äì30</td>\n",
       "      <td>0.543</td>\n",
       "      <td>151.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       image_name  cluster_id   AccoID  \\\n",
       "0  cluster_000_AccoID_1170854_20251107_091623.png           0  1170854   \n",
       "1  cluster_000_AccoID_1170854_20251107_091623.png           0  1170854   \n",
       "2  cluster_000_AccoID_1170854_20251107_091623.png           0  1170854   \n",
       "3  cluster_000_AccoID_1170854_20251107_091623.png           0  1170854   \n",
       "4  cluster_000_AccoID_1170854_20251107_091623.png           0  1170854   \n",
       "5  cluster_000_AccoID_1170854_20251107_091623.png           0  1170854   \n",
       "6  cluster_000_AccoID_1170854_20251107_091623.png           0  1170854   \n",
       "7  cluster_001_AccoID_1171262_20251107_112821.png           1  1171262   \n",
       "8  cluster_002_AccoID_1171659_20251107_135038.png           2  1171659   \n",
       "9  cluster_002_AccoID_1171659_20251107_135038.png           2  1171659   \n",
       "\n",
       "    AccoDocNo             AccoDate            timestamp  AccoAmount  Quantity  \\\n",
       "0   224882/14  2025-11-07 09:17:00  2025-11-07 09:16:23      -460.0       1.0   \n",
       "1   224882/14  2025-11-07 09:17:00  2025-11-07 09:16:23      -460.0       1.0   \n",
       "2   224882/14  2025-11-07 09:17:00  2025-11-07 09:16:23      -460.0       1.0   \n",
       "3   224882/14  2025-11-07 09:17:00  2025-11-07 09:16:23      -460.0       1.0   \n",
       "4   224882/14  2025-11-07 09:17:00  2025-11-07 09:16:23      -460.0       1.0   \n",
       "5   224882/14  2025-11-07 09:17:00  2025-11-07 09:16:23      -460.0       2.0   \n",
       "6   224882/14  2025-11-07 09:17:00  2025-11-07 09:16:23      -460.0       2.0   \n",
       "7   224949/77  2025-11-07 11:28:00  2025-11-07 11:28:21      -112.0       4.0   \n",
       "8  225013/151  2025-11-07 13:51:00  2025-11-07 13:50:38       -85.0       1.0   \n",
       "9  225013/151  2025-11-07 13:51:00  2025-11-07 13:50:38       -85.0       1.0   \n",
       "\n",
       "   Discount  UnitPrice  ...     StockDesciption predicted_gender confidence  \\\n",
       "0       0.0       29.0  ...     wors breakfast            Female      0.999   \n",
       "1       0.0       39.0  ...        plaas koffee           Female      0.999   \n",
       "2       0.0       20.0  ...    americano black            Female      0.999   \n",
       "3       0.0       29.0  ...          cappuccino           Female      0.999   \n",
       "4       0.0       59.0  ...                lite           Female      0.999   \n",
       "5       0.0       53.0  ...  pbb peanut butter            Female      0.999   \n",
       "6       0.0       89.0  ...              hadeda           Female      0.999   \n",
       "7       0.2       35.0  ...          beef patty           Female      0.970   \n",
       "8       0.0       36.0  ...          cappuccino           Female      0.948   \n",
       "9       0.0       49.0  ...           just pops           Female      0.948   \n",
       "\n",
       "  predicted_age  age_confidence  InvNo  survey_gender  survey_age_group  \\\n",
       "0         21‚Äì30           0.742   14.0              F             41‚Äì55   \n",
       "1         21‚Äì30           0.742   14.0              F             41‚Äì55   \n",
       "2         21‚Äì30           0.742   14.0              F             41‚Äì55   \n",
       "3         21‚Äì30           0.742   14.0              F             41‚Äì55   \n",
       "4         21‚Äì30           0.742   14.0              F             41‚Äì55   \n",
       "5         21‚Äì30           0.742   14.0              F             41‚Äì55   \n",
       "6         21‚Äì30           0.742   14.0              F             41‚Äì55   \n",
       "7         31‚Äì40           0.448   77.0           None              None   \n",
       "8         21‚Äì30           0.543  151.0           None              None   \n",
       "9         21‚Äì30           0.543  151.0           None              None   \n",
       "\n",
       "  survey_time survey_completed  \n",
       "0    08:57:00             True  \n",
       "1    08:57:00             True  \n",
       "2    08:57:00             True  \n",
       "3    08:57:00             True  \n",
       "4    08:57:00             True  \n",
       "5    08:57:00             True  \n",
       "6    08:57:00             True  \n",
       "7        None            False  \n",
       "8        None            False  \n",
       "9        None            False  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "# import chardet\n",
    "\n",
    "# # === PATHS ===\n",
    "# predictions_csv = \"../results/20251107/results_faces_accounting_20251107_vit.csv\"\n",
    "# survey_xlsx = \"../survey/Survey_Cafe_5-11-2025.xlsx\"\n",
    "# output_csv = \"../results/20251107/results_faces_accounting_20251107_vit_final.csv\"\n",
    "\n",
    "# # === SAFE LOAD: AUTO-DETECT ENCODING ===\n",
    "# with open(predictions_csv, \"rb\") as f:\n",
    "#     enc = chardet.detect(f.read())[\"encoding\"]\n",
    "# print(f\"üîç Detected encoding for predictions CSV: {enc}\")\n",
    "\n",
    "# pred_df = pd.read_csv(predictions_csv, encoding=enc, on_bad_lines=\"skip\", low_memory=False)\n",
    "# survey_df = pd.read_excel(survey_xlsx)\n",
    "\n",
    "# print(f\"‚úÖ Loaded {len(pred_df)} prediction records (items) and {len(survey_df)} survey entries.\\n\")\n",
    "\n",
    "# # === HANDLE TIMESTAMP COLUMN ===\n",
    "# if \"AccoDateStamp\" in pred_df.columns:\n",
    "#     pred_df.rename(columns={\"AccoDateStamp\": \"AccoTime\"}, inplace=True)\n",
    "\n",
    "# # === EXTRACT INVOICE NUMBER FROM AccoDocNo (e.g., 224673/155 ‚Üí 155) ===\n",
    "# pred_df[\"InvNo\"] = pred_df[\"AccoDocNo\"].astype(str).apply(\n",
    "#     lambda x: re.search(r\"/(\\d+)\", x).group(1) if re.search(r\"/(\\d+)\", x) else None\n",
    "# )\n",
    "# pred_df[\"InvNo\"] = pd.to_numeric(pred_df[\"InvNo\"], errors=\"coerce\")\n",
    "\n",
    "# print(\"üßæ Extracted InvNo from AccoDocNo ‚Äî sample:\")\n",
    "# print(pred_df[\"InvNo\"].dropna().head(), \"\\n\")\n",
    "\n",
    "# # === PREPARE SURVEY DATA ===\n",
    "# survey_df.columns = survey_df.columns.str.strip()\n",
    "# possible_inv_cols = [c for c in survey_df.columns if \"inv\" in c.lower()]\n",
    "# inv_col = possible_inv_cols[0] if possible_inv_cols else \"Inv No\"\n",
    "# print(f\"‚úÖ Using invoice column: '{inv_col}'\")\n",
    "\n",
    "# survey = survey_df.copy()\n",
    "# survey.rename(columns={\n",
    "#     inv_col: \"InvNo\",\n",
    "#     \"Sex\": \"survey_gender\",\n",
    "#     \"Time\": \"survey_time\"\n",
    "# }, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# # === COMBINE AGE BRACKETS (66‚Äì80 and 80+) ===\n",
    "# if \"80+\" in survey.columns:\n",
    "#     if \"66‚Äì80\" not in survey.columns:\n",
    "#         survey[\"66‚Äì80\"] = None\n",
    "#     survey[\"66‚Äì80\"] = survey[[\"66‚Äì80\", \"80+\"]].apply(\n",
    "#         lambda x: \"X\" if (\"X\" in str(x[0]).upper() or \"X\" in str(x[1]).upper()) else \"\",\n",
    "#         axis=1\n",
    "#     )\n",
    "#     print(\"üîÅ Merged '66‚Äì80' and '80+' into single bracket.\")\n",
    "\n",
    "# # === DETECT AGE GROUP FROM X MARKS ===\n",
    "# age_columns = [\"1‚Äì10\", \"11‚Äì20\", \"21‚Äì30\", \"31‚Äì40\", \"41‚Äì55\", \"56‚Äì65\", \"66‚Äì80\"]\n",
    "# survey[\"survey_age_group\"] = survey[age_columns].apply(\n",
    "#     lambda row: next((col for col in age_columns if str(row[col]).upper() == \"X\"), None),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # === NORMALIZE FORMATTING ===\n",
    "# merge_map = {\n",
    "#     \"1‚Äì10\": \"01‚Äì10\", \"11‚Äì20\": \"11‚Äì20\", \"21‚Äì30\": \"21‚Äì30\",\n",
    "#     \"31‚Äì40\": \"31‚Äì40\", \"41‚Äì55\": \"41‚Äì55\", \"56‚Äì65\": \"56‚Äì65\", \"66‚Äì80\": \"66‚Äì80\"\n",
    "# }\n",
    "# survey[\"survey_age_group\"] = survey[\"survey_age_group\"].map(merge_map)\n",
    "\n",
    "# # === SELECT RELEVANT FIELDS ===\n",
    "# survey = survey[[\"InvNo\", \"survey_gender\", \"survey_age_group\", \"survey_time\"]]\n",
    "# survey[\"InvNo\"] = pd.to_numeric(survey[\"InvNo\"], errors=\"coerce\")\n",
    "\n",
    "# print(f\"‚úÖ Survey cleaned ‚Äî {len(survey)} valid records with InvNo.\\n\")\n",
    "\n",
    "# # === MERGE (Many items to one survey) ===\n",
    "# merged = pred_df.merge(survey, on=\"InvNo\", how=\"left\")\n",
    "\n",
    "# # === RULE-BASED MATCHING FOR MULTIPLE RESPONDENTS ===\n",
    "# def best_survey_for_item(row):\n",
    "#     subset = survey[survey[\"InvNo\"] == row[\"InvNo\"]]\n",
    "#     if len(subset) == 0:\n",
    "#         return pd.Series({\"survey_gender\": None, \"survey_age_group\": None, \"survey_time\": None})\n",
    "#     if len(subset) == 1:\n",
    "#         return subset.iloc[0][[\"survey_gender\", \"survey_age_group\", \"survey_time\"]]\n",
    "\n",
    "#     # multiple respondents ‚Äî use simple demographic match\n",
    "#     subset = subset.copy()\n",
    "#     subset[\"score\"] = 0\n",
    "#     subset.loc[subset[\"survey_gender\"] == row[\"predicted_gender\"], \"score\"] += 1\n",
    "#     subset.loc[subset[\"survey_age_group\"] == row[\"predicted_age\"], \"score\"] += 1\n",
    "#     best = subset.sort_values(\"score\", ascending=False).iloc[0]\n",
    "#     return best[[\"survey_gender\", \"survey_age_group\", \"survey_time\"]]\n",
    "\n",
    "# for col in [\"survey_gender\", \"survey_age_group\", \"survey_time\"]:\n",
    "#     merged[col] = None\n",
    "\n",
    "# merged[[\"survey_gender\", \"survey_age_group\", \"survey_time\"]] = merged.apply(best_survey_for_item, axis=1)\n",
    "# merged[\"survey_completed\"] = merged[\"survey_gender\"].notna()\n",
    "\n",
    "# # === SAVE FINAL CSV ===\n",
    "# merged.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "# print(f\"\\n‚úÖ Final merged file saved: {output_csv}\")\n",
    "# print(f\"üìä Total rows: {len(merged)} | Completed surveys: {merged['survey_completed'].sum()}\\n\")\n",
    "# display(merged.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "810a5f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Detected encoding for predictions CSV: utf-8\n",
      "‚úÖ Loaded 735 prediction records and 61 survey entries.\n",
      "\n",
      "‚úÖ Saved merged file: ../results/20251107/results_faces_accounting_20251107_vit_final.csv\n",
      "üìä Total rows: 894 | Completed surveys: 384\n",
      "\n",
      "üìä Survey Gender Distribution:\n",
      "survey_gender\n",
      "None      510\n",
      "Female    300\n",
      "Male       84\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import chardet\n",
    "\n",
    "# === PATHS ===\n",
    "predictions_csv = \"../results/20251107/results_faces_accounting_20251107_vit.csv\"\n",
    "survey_xlsx = \"../survey/Survey_Cafe_7-11-2025.xlsx\"\n",
    "output_csv = \"../results/20251107/results_faces_accounting_20251107_vit_final.csv\"\n",
    "\n",
    "# === LOAD WITH SAFE ENCODING DETECTION ===\n",
    "with open(predictions_csv, \"rb\") as f:\n",
    "    enc = chardet.detect(f.read())[\"encoding\"]\n",
    "print(f\"üîç Detected encoding for predictions CSV: {enc}\")\n",
    "\n",
    "pred_df = pd.read_csv(predictions_csv, encoding=enc, on_bad_lines=\"skip\", low_memory=False)\n",
    "survey_df = pd.read_excel(survey_xlsx)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(pred_df)} prediction records and {len(survey_df)} survey entries.\\n\")\n",
    "\n",
    "# === EXTRACT InvNo FROM AccoDocNo ===\n",
    "if \"AccoDocNo\" in pred_df.columns:\n",
    "    pred_df[\"InvNo\"] = pred_df[\"AccoDocNo\"].astype(str).str.extract(r\"/(\\d+)\", expand=False)\n",
    "pred_df[\"InvNo\"] = pd.to_numeric(pred_df[\"InvNo\"], errors=\"coerce\")\n",
    "\n",
    "# === NORMALIZE SURVEY COLUMN NAMES ===\n",
    "def normalize_col(c: str) -> str:\n",
    "    c = str(c).strip()\n",
    "    c = re.sub(r\"\\s+\", \" \", c.replace(\"\\xa0\", \" \"))\n",
    "    c = c.replace(\"‚Äì\", \"-\").replace(\"‚Äî\", \"-\")\n",
    "    return c\n",
    "\n",
    "survey_df.columns = [normalize_col(c) for c in survey_df.columns]\n",
    "\n",
    "# === FIND AND RENAME INVOICE COLUMN ===\n",
    "inv_candidates = [c for c in survey_df.columns if \"inv\" in c.lower()]\n",
    "if not inv_candidates:\n",
    "    raise KeyError(\"‚ùå No invoice column found in survey sheet.\")\n",
    "inv_col = inv_candidates[0]\n",
    "if inv_col != \"InvNo\":\n",
    "    survey_df.rename(columns={inv_col: \"InvNo\"}, inplace=True)\n",
    "\n",
    "# === RENAME STANDARD COLUMNS ===\n",
    "rename_map = {}\n",
    "if \"Sex\" in survey_df.columns:\n",
    "    rename_map[\"Sex\"] = \"survey_gender\"\n",
    "if \"Time\" in survey_df.columns:\n",
    "    rename_map[\"Time\"] = \"survey_time\"\n",
    "survey_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# === NORMALIZE AGE COLUMNS ===\n",
    "canonical_age_headers = [\"1-10\", \"11-20\", \"21-30\", \"31-40\", \"41-55\", \"56-65\", \"66-80\", \"80+\"]\n",
    "age_cols = [c for c in survey_df.columns if c in canonical_age_headers]\n",
    "if not age_cols:\n",
    "    # fallback pattern for dash variants\n",
    "    age_cols = [c for c in survey_df.columns if re.match(r\"^\\d+\\s*[-‚Äì‚Äî]\\s*\\d+$\", c) or c.strip().endswith(\"+\")]\n",
    "if not age_cols:\n",
    "    raise KeyError(\"‚ùå Could not find any age columns in survey sheet.\")\n",
    "\n",
    "# === MERGE 66‚Äì80 and 80+ ===\n",
    "if \"80+\" in survey_df.columns:\n",
    "    if \"66-80\" not in survey_df.columns:\n",
    "        survey_df[\"66-80\"] = \"\"\n",
    "    survey_df[\"66-80\"] = survey_df[[\"66-80\", \"80+\"]].apply(\n",
    "        lambda x: \"X\" if (\"X\" in str(x[0]).upper() or \"X\" in str(x[1]).upper()) else \"\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# === DETECT survey_age_group FROM X ===\n",
    "def pick_age(row):\n",
    "    for c in age_cols:\n",
    "        if str(row[c]).strip().upper() == \"X\":\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "survey_df[\"survey_age_group\"] = survey_df.apply(pick_age, axis=1)\n",
    "\n",
    "# === KEEP ONLY RELEVANT COLUMNS ===\n",
    "cols = [\"InvNo\", \"survey_gender\", \"survey_age_group\"]\n",
    "if \"survey_time\" in survey_df.columns:\n",
    "    cols.append(\"survey_time\")\n",
    "\n",
    "survey = survey_df[cols].copy()\n",
    "survey[\"InvNo\"] = pd.to_numeric(survey[\"InvNo\"], errors=\"coerce\")\n",
    "\n",
    "# === NORMALIZE GENDER TEXT ===\n",
    "survey[\"survey_gender\"] = (\n",
    "    survey[\"survey_gender\"]\n",
    "    .astype(str).str.strip().str.upper()\n",
    "    .replace({\"M\": \"Male\", \"MALE\": \"Male\", \"F\": \"Female\", \"FEMALE\": \"Female\"})\n",
    ")\n",
    "\n",
    "# === MERGE PREDICTIONS WITH SURVEY ===\n",
    "merged = pred_df.merge(survey, on=\"InvNo\", how=\"left\")\n",
    "\n",
    "# === HANDLE MULTIPLE SURVEYS PER INVOICE ===\n",
    "def best_survey_for_item(row):\n",
    "    subset = survey[survey[\"InvNo\"] == row[\"InvNo\"]]\n",
    "    if len(subset) == 0:\n",
    "        return pd.Series({\"survey_gender\": None, \"survey_age_group\": None, \"survey_time\": None})\n",
    "    if len(subset) == 1:\n",
    "        return subset.iloc[0][[\"survey_gender\", \"survey_age_group\", \"survey_time\"]]\n",
    "    subset = subset.copy()\n",
    "    subset[\"score\"] = 0\n",
    "    if \"predicted_gender\" in row:\n",
    "        subset.loc[subset[\"survey_gender\"] == row[\"predicted_gender\"], \"score\"] += 1\n",
    "    if \"predicted_age\" in row:\n",
    "        subset.loc[subset[\"survey_age_group\"] == row[\"predicted_age\"], \"score\"] += 1\n",
    "    best = subset.sort_values(\"score\", ascending=False).iloc[0]\n",
    "    return best[[\"survey_gender\", \"survey_age_group\", \"survey_time\"]]\n",
    "\n",
    "# Apply selection\n",
    "replacement = merged.apply(best_survey_for_item, axis=1)\n",
    "for c in [\"survey_gender\", \"survey_age_group\", \"survey_time\"]:\n",
    "    merged[c] = replacement[c]\n",
    "\n",
    "# === ADD SURVEY COMPLETION FLAG ===\n",
    "merged[\"survey_completed\"] = merged[\"survey_gender\"].notna()\n",
    "\n",
    "# === SAVE FINAL FILE ===\n",
    "merged.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"‚úÖ Saved merged file: {output_csv}\")\n",
    "print(f\"üìä Total rows: {len(merged)} | Completed surveys: {merged['survey_completed'].sum()}\")\n",
    "\n",
    "# === SUMMARY CHECK ===\n",
    "print(\"\\nüìä Survey Gender Distribution:\")\n",
    "print(merged[\"survey_gender\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f454e25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Combined CSVs created:\n",
      " - ..\\results\\combined_dates\\combined_dates_final.csv\n",
      " - ..\\results\\combined_dates\\combined_dates_vit_final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths to your four original processed CSVs\n",
    "csv1 = \"../results/20251105/results_faces_accounting_20251105_final.csv\"\n",
    "csv2 = \"../results/20251107/results_faces_accounting_20251107_final.csv\"\n",
    "\n",
    "csv3 = \"../results/20251105/results_faces_accounting_20251105_vit_final.csv\"\n",
    "csv4 = \"../results/20251107/results_faces_accounting_20251107_vit_final.csv\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Load safely (automatic UTF-8 fallback)\n",
    "# -------------------------------------------------------------------\n",
    "def safe_read(path):\n",
    "    try:\n",
    "        return pd.read_csv(path, encoding=\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, encoding=\"cp1252\")\n",
    "\n",
    "# Read all four\n",
    "df_05_final = safe_read(csv1)\n",
    "df_07_final = safe_read(csv2)\n",
    "\n",
    "df_05_vit = safe_read(csv3)\n",
    "df_07_vit = safe_read(csv4)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Combine them\n",
    "# -------------------------------------------------------------------\n",
    "combined_final = pd.concat([df_05_final, df_07_final], ignore_index=True)\n",
    "combined_vit_final = pd.concat([df_05_vit, df_07_vit], ignore_index=True)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Export clean, UTF-8 encoded combined datasets\n",
    "# -------------------------------------------------------------------\n",
    "output_dir = Path(\"../results/combined_dates\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "combined_final_path = output_dir / \"combined_dates_final.csv\"\n",
    "combined_vit_final_path = output_dir / \"combined_dates_vit_final.csv\"\n",
    "\n",
    "combined_final.to_csv(combined_final_path, index=False, encoding=\"utf-8\")\n",
    "combined_vit_final.to_csv(combined_vit_final_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"‚úî Combined CSVs created:\")\n",
    "print(\" -\", combined_final_path)\n",
    "print(\" -\", combined_vit_final_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e4d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
