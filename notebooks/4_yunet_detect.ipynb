{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da15a102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Processing 29214 person crops...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29214/29214 [2:11:11<00:00,  3.71it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Enhanced face crops saved to: ../data/crops_face/20251105/1_cafe_pos_person_faces_yunet\n",
      "ðŸ“¸ Total cropped faces: 7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# LIGHT PREPROCESSING + FACE DETECTION PIPELINE (Linked with AccoID & Timestamp)\n",
    "# ===============================================\n",
    "from deepface import DeepFace\n",
    "import cv2, os, re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "INPUT_DIR = \"../data/crops_person/cafe_POS_person_crops_2025_11_05\"\n",
    "OUTPUT_DIR = \"../data/crops_face/20251105/1_cafe_pos_person_faces_yunet\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "DETECTOR = \"yunet\"  # Best for CCTV / varied angles\n",
    "ENFORCE_DETECTION = True\n",
    "MIN_CONFIDENCE = 0.65\n",
    "TARGET_MIN = 192\n",
    "TARGET_MAX = 384\n",
    "EXPAND_RATIO = 0.5  # Include gentle context (hair/shoulders)\n",
    "\n",
    "# === LIGHT IMAGE PREPROCESSING ===\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "def preprocess_soft(img):\n",
    "    \"\"\"Subtle enhancement for better detection without altering tone.\"\"\"\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    l = clahe.apply(l)\n",
    "    lab = cv2.merge((l, a, b))\n",
    "    img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Gentle gamma correction\n",
    "    gamma = 1.08\n",
    "    lut = np.array([((i / 255.0) ** (1 / gamma)) * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "    img = cv2.LUT(img, lut)\n",
    "\n",
    "    # Mild denoising\n",
    "    img = cv2.fastNlMeansDenoisingColored(img, None, 3, 3, 5, 15)\n",
    "    return img\n",
    "\n",
    "# === FILENAME PARSING FUNCTION ===\n",
    "def parse_filename_for_info(filename):\n",
    "    \"\"\"\n",
    "    Expected pattern: AccoID_1147705_20251019_083301_person_0.jpg\n",
    "    Extract AccoID and timestamp.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"AccoID_(\\d+)_(\\d{8}_\\d{6})\", filename)\n",
    "    if match:\n",
    "        acco_id = match.group(1)\n",
    "        timestamp = match.group(2)\n",
    "    else:\n",
    "        acco_id, timestamp = \"unknown\", \"00000000_000000\"\n",
    "    return acco_id, timestamp\n",
    "\n",
    "# === PROCESSING LOOP ===\n",
    "images = sorted([f for f in os.listdir(INPUT_DIR) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "print(f\"ðŸ§  Processing {len(images)} person crops...\")\n",
    "\n",
    "for i, img_name in enumerate(tqdm(images)):\n",
    "    img_path = os.path.join(INPUT_DIR, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    acco_id, timestamp = parse_filename_for_info(img_name)\n",
    "    img = preprocess_soft(img)\n",
    "    h_img, w_img = img.shape[:2]\n",
    "\n",
    "    try:\n",
    "        detections = DeepFace.extract_faces(\n",
    "            img_path=img_path,\n",
    "            detector_backend=DETECTOR,\n",
    "            enforce_detection=ENFORCE_DETECTION,\n",
    "            align=False\n",
    "        )\n",
    "\n",
    "        if not detections:\n",
    "            continue\n",
    "\n",
    "        for j, face_info in enumerate(detections):\n",
    "            conf = face_info.get(\"confidence\", 1.0)\n",
    "            if conf < MIN_CONFIDENCE:\n",
    "                continue\n",
    "\n",
    "            area = face_info.get(\"facial_area\", {})\n",
    "            if not area:\n",
    "                continue\n",
    "\n",
    "            x, y, w, h = area[\"x\"], area[\"y\"], area[\"w\"], area[\"h\"]\n",
    "\n",
    "            # --- Adaptive crop with soft padding ---\n",
    "            dx, dy = int(w * EXPAND_RATIO), int(h * EXPAND_RATIO)\n",
    "            x1, y1 = max(x - dx, 0), max(y - dy, 0)\n",
    "            x2, y2 = min(x + w + dx, w_img), min(y + h + dy, h_img)\n",
    "            face_crop = img[y1:y2, x1:x2]\n",
    "\n",
    "            # --- Adaptive resize ---\n",
    "            h, w = face_crop.shape[:2]\n",
    "            scale = min(max(TARGET_MIN / min(h, w), 1.0), TARGET_MAX / max(h, w))\n",
    "            new_size = (int(w * scale), int(h * scale))\n",
    "            face_crop = cv2.resize(face_crop, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            # --- Save with AccoID & Timestamp in name ---\n",
    "            out_name = f\"AccoID_{acco_id}_{timestamp}.jpg\"\n",
    "            out_path = os.path.join(OUTPUT_DIR, out_name)\n",
    "            cv2.imwrite(out_path, face_crop, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "\n",
    "    except Exception as e:\n",
    "        #print(f\"âš ï¸ Error processing {img_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nâœ… Enhanced face crops saved to: {OUTPUT_DIR}\")\n",
    "print(f\"ðŸ“¸ Total cropped faces: {len(os.listdir(OUTPUT_DIR))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d47574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Processing 27340 person crops...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27340/27340 [2:05:01<00:00,  3.64it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Enhanced face crops saved to: ../data/crops_face/20251107/1_cafe_pos_person_faces_yunet\n",
      "ðŸ“¸ Total cropped faces: 7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# LIGHT PREPROCESSING + FACE DETECTION PIPELINE (Linked with AccoID & Timestamp)\n",
    "# ===============================================\n",
    "from deepface import DeepFace\n",
    "import cv2, os, re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "INPUT_DIR = \"../data/crops_person/cafe_POS_person_crops_2025_11_07\"\n",
    "OUTPUT_DIR = \"../data/crops_face/20251107/1_cafe_pos_person_faces_yunet\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "DETECTOR = \"yunet\"  # Best for CCTV / varied angles\n",
    "ENFORCE_DETECTION = True\n",
    "MIN_CONFIDENCE = 0.65\n",
    "TARGET_MIN = 192\n",
    "TARGET_MAX = 384\n",
    "EXPAND_RATIO = 0.5  # Include gentle context (hair/shoulders)\n",
    "\n",
    "# === LIGHT IMAGE PREPROCESSING ===\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "def preprocess_soft(img):\n",
    "    \"\"\"Subtle enhancement for better detection without altering tone.\"\"\"\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    l = clahe.apply(l)\n",
    "    lab = cv2.merge((l, a, b))\n",
    "    img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Gentle gamma correction\n",
    "    gamma = 1.08\n",
    "    lut = np.array([((i / 255.0) ** (1 / gamma)) * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "    img = cv2.LUT(img, lut)\n",
    "\n",
    "    # Mild denoising\n",
    "    img = cv2.fastNlMeansDenoisingColored(img, None, 3, 3, 5, 15)\n",
    "    return img\n",
    "\n",
    "# === FILENAME PARSING FUNCTION ===\n",
    "def parse_filename_for_info(filename):\n",
    "    \"\"\"\n",
    "    Expected pattern: AccoID_1147705_20251019_083301_person_0.jpg\n",
    "    Extract AccoID and timestamp.\n",
    "    \"\"\"\n",
    "    match = re.search(r\"AccoID_(\\d+)_(\\d{8}_\\d{6})\", filename)\n",
    "    if match:\n",
    "        acco_id = match.group(1)\n",
    "        timestamp = match.group(2)\n",
    "    else:\n",
    "        acco_id, timestamp = \"unknown\", \"00000000_000000\"\n",
    "    return acco_id, timestamp\n",
    "\n",
    "# === PROCESSING LOOP ===\n",
    "images = sorted([f for f in os.listdir(INPUT_DIR) if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "print(f\"ðŸ§  Processing {len(images)} person crops...\")\n",
    "\n",
    "for i, img_name in enumerate(tqdm(images)):\n",
    "    img_path = os.path.join(INPUT_DIR, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    acco_id, timestamp = parse_filename_for_info(img_name)\n",
    "    img = preprocess_soft(img)\n",
    "    h_img, w_img = img.shape[:2]\n",
    "\n",
    "    try:\n",
    "        detections = DeepFace.extract_faces(\n",
    "            img_path=img_path,\n",
    "            detector_backend=DETECTOR,\n",
    "            enforce_detection=ENFORCE_DETECTION,\n",
    "            align=False\n",
    "        )\n",
    "\n",
    "        if not detections:\n",
    "            continue\n",
    "\n",
    "        for j, face_info in enumerate(detections):\n",
    "            conf = face_info.get(\"confidence\", 1.0)\n",
    "            if conf < MIN_CONFIDENCE:\n",
    "                continue\n",
    "\n",
    "            area = face_info.get(\"facial_area\", {})\n",
    "            if not area:\n",
    "                continue\n",
    "\n",
    "            x, y, w, h = area[\"x\"], area[\"y\"], area[\"w\"], area[\"h\"]\n",
    "\n",
    "            # --- Adaptive crop with soft padding ---\n",
    "            dx, dy = int(w * EXPAND_RATIO), int(h * EXPAND_RATIO)\n",
    "            x1, y1 = max(x - dx, 0), max(y - dy, 0)\n",
    "            x2, y2 = min(x + w + dx, w_img), min(y + h + dy, h_img)\n",
    "            face_crop = img[y1:y2, x1:x2]\n",
    "\n",
    "            # --- Adaptive resize ---\n",
    "            h, w = face_crop.shape[:2]\n",
    "            scale = min(max(TARGET_MIN / min(h, w), 1.0), TARGET_MAX / max(h, w))\n",
    "            new_size = (int(w * scale), int(h * scale))\n",
    "            face_crop = cv2.resize(face_crop, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            # --- Save with AccoID & Timestamp in name ---\n",
    "            out_name = f\"AccoID_{acco_id}_{timestamp}.jpg\"\n",
    "            out_path = os.path.join(OUTPUT_DIR, out_name)\n",
    "            cv2.imwrite(out_path, face_crop, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "\n",
    "    except Exception as e:\n",
    "        #print(f\"âš ï¸ Error processing {img_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nâœ… Enhanced face crops saved to: {OUTPUT_DIR}\")\n",
    "print(f\"ðŸ“¸ Total cropped faces: {len(os.listdir(OUTPUT_DIR))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
