{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ee618df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning clusters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 287/287 [00:00<00:00, 2249.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Clusterâ€“AccoID diversity summary saved â†’ ../data/cluster_accid_diversity_20251105.csv\n",
      "           cluster  num_unique_orders  \\\n",
      "286  cluster_noise                148   \n",
      "160    cluster_173                 13   \n",
      "274    cluster_295                 12   \n",
      "273    cluster_294                 11   \n",
      "275    cluster_296                  9   \n",
      "277    cluster_298                  9   \n",
      "285    cluster_306                  8   \n",
      "124    cluster_131                  7   \n",
      "206    cluster_222                  7   \n",
      "281    cluster_302                  7   \n",
      "\n",
      "                                               accoids  \n",
      "286  [1168504, 1168525, 1168530, 1168537, 1168544, ...  \n",
      "160  [1168755, 1168760, 1169052, 1169098, 1169105, ...  \n",
      "274  [1168537, 1168544, 1168755, 1168760, 1168869, ...  \n",
      "273  [1168525, 1168552, 1168559, 1168564, 1168788, ...  \n",
      "275  [1168626, 1168633, 1168715, 1168722, 1168748, ...  \n",
      "277  [1168811, 1169239, 1169272, 1169279, 1169286, ...  \n",
      "285  [1168602, 1168833, 1168840, 1168902, 1168907, ...  \n",
      "124  [1169322, 1169341, 1169348, 1169355, 1169360, ...  \n",
      "206  [1169038, 1169623, 1169630, 1169635, 1169640, ...  \n",
      "281  [1168626, 1168633, 1168640, 1168647, 1168652, ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Paths ===\n",
    "CLUSTER_BASE = r\"../data/crops_face/20251105/4_cafe_pos_cluster_faces\"\n",
    "OUTPUT_CSV   = r\"../data/cluster_accid_diversity_20251105.csv\"\n",
    "\n",
    "# === Regex Helper ===\n",
    "re_accoid = re.compile(r\"AccoID_(\\d+)\")\n",
    "\n",
    "records = []\n",
    "\n",
    "# === Iterate through cluster folders ===\n",
    "for cluster in tqdm(sorted(os.listdir(CLUSTER_BASE)), desc=\"Scanning clusters\"):\n",
    "    cluster_path = os.path.join(CLUSTER_BASE, cluster)\n",
    "    if not os.path.isdir(cluster_path):\n",
    "        continue\n",
    "\n",
    "    accoids = set()  # store unique order IDs for this cluster\n",
    "\n",
    "    for fname in os.listdir(cluster_path):\n",
    "        if not fname.lower().endswith((\".jpg\", \".png\")):\n",
    "            continue\n",
    "\n",
    "        match = re_accoid.search(fname)\n",
    "        if match:\n",
    "            accoids.add(int(match.group(1)))\n",
    "\n",
    "    # Record summary for this cluster\n",
    "    records.append({\n",
    "        \"cluster\": cluster,\n",
    "        \"num_unique_orders\": len(accoids),\n",
    "        \"accoids\": sorted(list(accoids))\n",
    "    })\n",
    "\n",
    "# === Convert to DataFrame ===\n",
    "df = pd.DataFrame(records)\n",
    "df = df.sort_values(\"num_unique_orders\", ascending=False)\n",
    "\n",
    "# === Save ===\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"\\nâœ… Clusterâ€“AccoID diversity summary saved â†’ {OUTPUT_CSV}\")\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27ed7d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Found 287 clusters to process.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering clusters by most common AccoID:   0%|          | 0/287 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering clusters by most common AccoID: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 287/287 [00:22<00:00, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Filtering complete!\n",
      "ðŸ“‚ Filtered clusters saved to: ../data/crops_face/20251105/4_cafe_pos_cluster_faces_filtered\n",
      "\n",
      "ðŸ§¾ Unique AccoID count after filtering: 136\n",
      "ðŸ’¾ Detailed mapping saved to filtered_orders_summary.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# === PATHS ===\n",
    "SRC_BASE = r\"../data/crops_face/20251105/4_cafe_pos_cluster_faces\"       # original clusters\n",
    "OUT_BASE = r\"../data/crops_face/20251105/4_cafe_pos_cluster_faces_filtered\"  # output folder\n",
    "os.makedirs(OUT_BASE, exist_ok=True)\n",
    "\n",
    "# === Helper: Extract AccoID from filename ===\n",
    "def extract_accoid(filename):\n",
    "    \"\"\"\n",
    "    Extract AccoID from filename pattern like:\n",
    "    AccoID_1150642_20251021_110849.jpg\n",
    "    \"\"\"\n",
    "    match = re.search(r\"AccoID_(\\d+)\", filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "\n",
    "# === STEP 1: FILTER CLUSTERS TO KEEP MOST FREQUENT ACCOID ===\n",
    "clusters = [\n",
    "    d for d in os.listdir(SRC_BASE)\n",
    "    if d.startswith(\"cluster_\") and os.path.isdir(os.path.join(SRC_BASE, d))\n",
    "]\n",
    "print(f\"ðŸ§  Found {len(clusters)} clusters to process.\\n\")\n",
    "\n",
    "filtered_rows = []  # for unique count later\n",
    "\n",
    "for cluster in tqdm(clusters, desc=\"Filtering clusters by most common AccoID\"):\n",
    "    cluster_path = os.path.join(SRC_BASE, cluster)\n",
    "    out_cluster = os.path.join(OUT_BASE, cluster)\n",
    "    os.makedirs(out_cluster, exist_ok=True)\n",
    "\n",
    "    files = [f for f in os.listdir(cluster_path) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "    if not files:\n",
    "        continue\n",
    "\n",
    "    # Extract AccoIDs\n",
    "    accoids = [extract_accoid(f) for f in files if extract_accoid(f) is not None]\n",
    "    if not accoids:\n",
    "        continue\n",
    "\n",
    "    # Find most common AccoID\n",
    "    most_common_accoid, count = Counter(accoids).most_common(1)[0]\n",
    "\n",
    "    # Copy only files matching that AccoID\n",
    "    for f in files:\n",
    "        if most_common_accoid in f:\n",
    "            shutil.copy2(os.path.join(cluster_path, f), os.path.join(out_cluster, f))\n",
    "            filtered_rows.append({\n",
    "                \"cluster\": cluster,\n",
    "                \"file\": f,\n",
    "                \"AccoID\": most_common_accoid\n",
    "            })\n",
    "\n",
    "print(\"\\nâœ… Filtering complete!\")\n",
    "print(f\"ðŸ“‚ Filtered clusters saved to: {OUT_BASE}\")\n",
    "\n",
    "# === STEP 2: UNIQUE ORDER COUNT ===\n",
    "filtered_df = pd.DataFrame(filtered_rows)\n",
    "unique_orders = filtered_df[\"AccoID\"].nunique()\n",
    "\n",
    "print(f\"\\nðŸ§¾ Unique AccoID count after filtering: {unique_orders}\")\n",
    "print(f\"ðŸ’¾ Detailed mapping saved to filtered_orders_summary.csv\")\n",
    "\n",
    "filtered_df.to_csv(os.path.join(OUT_BASE, \"filtered_orders_summary.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb157ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning clusters: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 288/288 [00:00<00:00, 3950.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Clusterâ€“AccoID diversity summary saved â†’ ../data/cluster_accid_diversity_20251107_2.csv\n",
      "         cluster  num_unique_orders    accoids\n",
      "0    cluster_000                  1  [1169434]\n",
      "189  cluster_205                  1  [1169038]\n",
      "195  cluster_211                  1  [1169514]\n",
      "194  cluster_210                  1  [1169623]\n",
      "193  cluster_209                  1  [1169057]\n",
      "192  cluster_208                  1  [1169182]\n",
      "191  cluster_207                  1  [1168576]\n",
      "190  cluster_206                  1  [1168590]\n",
      "188  cluster_203                  1  [1169136]\n",
      "197  cluster_213                  1  [1169019]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Paths ===\n",
    "CLUSTER_BASE = r\"../data/crops_face/20251105/4_cafe_pos_cluster_faces_filtered\"\n",
    "OUTPUT_CSV   = r\"../data/cluster_accid_diversity_20251107_2.csv\"\n",
    "\n",
    "# === Regex Helper ===\n",
    "re_accoid = re.compile(r\"AccoID_(\\d+)\")\n",
    "\n",
    "records = []\n",
    "\n",
    "# === Iterate through cluster folders ===\n",
    "for cluster in tqdm(sorted(os.listdir(CLUSTER_BASE)), desc=\"Scanning clusters\"):\n",
    "    cluster_path = os.path.join(CLUSTER_BASE, cluster)\n",
    "    if not os.path.isdir(cluster_path):\n",
    "        continue\n",
    "\n",
    "    accoids = set()  # store unique order IDs for this cluster\n",
    "\n",
    "    for fname in os.listdir(cluster_path):\n",
    "        if not fname.lower().endswith((\".jpg\", \".png\")):\n",
    "            continue\n",
    "\n",
    "        match = re_accoid.search(fname)\n",
    "        if match:\n",
    "            accoids.add(int(match.group(1)))\n",
    "\n",
    "    # Record summary for this cluster\n",
    "    records.append({\n",
    "        \"cluster\": cluster,\n",
    "        \"num_unique_orders\": len(accoids),\n",
    "        \"accoids\": sorted(list(accoids))\n",
    "    })\n",
    "\n",
    "# === Convert to DataFrame ===\n",
    "df = pd.DataFrame(records)\n",
    "df = df.sort_values(\"num_unique_orders\", ascending=False)\n",
    "\n",
    "# === Save ===\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"\\nâœ… Clusterâ€“AccoID diversity summary saved â†’ {OUTPUT_CSV}\")\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20d7fe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Found 287 clusters to process for frontal face selection.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting most frontal face: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 287/287 [06:24<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Most frontal face per cluster saved to: ../data/crops_face/20251105/5_cafe_pos_faces_unique\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === PATHS ===\n",
    "SRC_BASE = r\"../data/crops_face/20251105/4_cafe_pos_cluster_faces_filtered\"\n",
    "OUT_BASE = r\"../data/crops_face/20251105/5_cafe_pos_faces_unique\"\n",
    "os.makedirs(OUT_BASE, exist_ok=True)\n",
    "\n",
    "# === Load Haar Cascade (for frontal face detection) ===\n",
    "face_cascade = cv2.CascadeClassifier(\"../models/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def frontal_score(img):\n",
    "    \"\"\"\n",
    "    Compute a score indicating how 'frontal' the face is.\n",
    "    Higher = more frontal.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4, minSize=(40, 40))\n",
    "    if len(faces) == 0:\n",
    "        return 0.0  # no face detected = bad candidate\n",
    "\n",
    "    # Choose largest detected face\n",
    "    x, y, w, h = max(faces, key=lambda f: f[2] * f[3])\n",
    "\n",
    "    img_h, img_w = gray.shape\n",
    "    face_center_x = x + w / 2\n",
    "    img_center_x = img_w / 2\n",
    "    center_offset = abs(face_center_x - img_center_x) / img_center_x  # 0 = perfectly centered\n",
    "\n",
    "    aspect_ratio = w / float(h)\n",
    "    aspect_score = 1 - abs(1 - aspect_ratio)  # closer to 1 = more frontal\n",
    "    center_score = 1 - center_offset  # closer to center = better\n",
    "\n",
    "    # Combine into final frontalness score\n",
    "    return (aspect_score * 0.9) + (center_score * 0.1)\n",
    "\n",
    "# === Iterate through clusters ===\n",
    "clusters = [\n",
    "    d for d in os.listdir(SRC_BASE)\n",
    "    if d.startswith(\"cluster_\") and os.path.isdir(os.path.join(SRC_BASE, d))\n",
    "]\n",
    "\n",
    "print(f\"ðŸ§  Found {len(clusters)} clusters to process for frontal face selection.\\n\")\n",
    "\n",
    "for cluster in tqdm(clusters, desc=\"Selecting most frontal face\"):\n",
    "    cluster_path = os.path.join(SRC_BASE, cluster)\n",
    "    files = [f for f in os.listdir(cluster_path) if f.lower().endswith((\".jpg\", \".png\"))]\n",
    "    if not files:\n",
    "        continue\n",
    "\n",
    "    best_file = None\n",
    "    best_score = -1\n",
    "\n",
    "    for f in files:\n",
    "        img_path = os.path.join(cluster_path, f)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        score = frontal_score(img)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_file = f\n",
    "\n",
    "    if best_file:\n",
    "        src_path = os.path.join(cluster_path, best_file)\n",
    "        dst_path = os.path.join(OUT_BASE, f\"{cluster}_{best_file}\")\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "print(f\"\\nâœ… Most frontal face per cluster saved to: {OUT_BASE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0bd56c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Directory containing unique faces\n",
    "folder = \"../data/crops_face/20251107/5_cafe_pos_faces_unique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5d36a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       image_name  cluster_id   AccoID  \\\n",
      "0  cluster_000_AccoID_1170854_20251107_091623.png           0  1170854   \n",
      "1  cluster_001_AccoID_1171262_20251107_112821.png           1  1171262   \n",
      "2  cluster_002_AccoID_1171659_20251107_135038.png           2  1171659   \n",
      "3  cluster_004_AccoID_1171659_20251107_135011.png           4  1171659   \n",
      "4  cluster_006_AccoID_1171574_20251107_132453.png           6  1171574   \n",
      "\n",
      "            timestamp  \n",
      "0 2025-11-07 09:16:23  \n",
      "1 2025-11-07 11:28:21  \n",
      "2 2025-11-07 13:50:38  \n",
      "3 2025-11-07 13:50:11  \n",
      "4 2025-11-07 13:24:53  \n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for file in os.listdir(folder):\n",
    "    if file.lower().endswith(('.jpg', '.png')):\n",
    "        match = re.match(r\"cluster_(\\d+)_AccoID_(\\d+)_(\\d{8})_(\\d{6})\", file)\n",
    "        if match:\n",
    "            cluster_id, acco_id, date_str, time_str = match.groups()\n",
    "            timestamp = datetime.strptime(date_str + time_str, \"%Y%m%d%H%M%S\")\n",
    "            records.append({\n",
    "                \"image_name\": file,\n",
    "                \"cluster_id\": int(cluster_id),\n",
    "                \"AccoID\": int(acco_id),\n",
    "                \"timestamp\": timestamp\n",
    "            })\n",
    "\n",
    "faces_df = pd.DataFrame(records)\n",
    "print(faces_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "81e55df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load accounting data\n",
    "acc = pd.read_csv(\"../db/cafe_pos_2025-11-07.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d9e2f642",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = acc[[\n",
    "    \"AccoID\", \"AccoDate\", \"AccoDocNo\", \"AccoAmount\",\n",
    "    \"Quantity\", \"Discount\", \"UnitPrice\",\n",
    "    \"StockCateDesc\", \"StockName\", \"StockDesciption\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7f17c965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Stage 1 results saved\n"
     ]
    }
   ],
   "source": [
    "merged = faces_df.merge(acc, on=\"AccoID\", how=\"left\")\n",
    "\n",
    "merged = merged[[\n",
    "    \"image_name\", \"cluster_id\", \"AccoID\", \"AccoDocNo\", \"AccoDate\",\n",
    "    \"timestamp\", \"AccoAmount\", \"Quantity\", \"Discount\", \"UnitPrice\",\n",
    "    \"StockCateDesc\", \"StockName\", \"StockDesciption\"\n",
    "]]\n",
    "\n",
    "# Save as first draft result CSV\n",
    "merged.to_csv(\"../results/20251107/results_faces_accounting_20251107.csv\", index=False)\n",
    "print(\"âœ… Stage 1 results saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73092e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
